import streamlit as st
import fitz  # PyMuPDF
from openai import OpenAI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ ì¬ìš° Custom AI", page_icon="ğŸ“„", layout="wide")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "page_num" not in st.session_state:
    st.session_state.page_num = 0
if "processed_data" not in st.session_state:
    st.session_state.processed_data = {}
if "full_text" not in st.session_state:
    st.session_state.full_text = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --- CSS ìŠ¤íƒ€ì¼ (ë„ˆë¹„ ì¡°ì ˆ ë° êµ¬ë¶„ì„ ) ---
st.markdown(
    """
    <style>
    section[data-testid="stSidebar"] { width: 200px !important; min-width: 200px !important; }
    [data-testid="column"] { border-right: 2px solid #000000 !important; padding: 0 15px !important; }
    [data-testid="column"]:last-child { border-right: none !important; }
    .stMarkdown { word-break: keep-all; }
    /* ì±„íŒ…ì°½ ì˜ì—­ ìŠ¤íƒ€ì¼ */
    .chat-container { border: 1px solid #ddd; padding: 10px; border-radius: 5px; background: #f9f9f9; height: 300px; overflow-y: auto; }
    </style>
    """,
    unsafe_allow_html=True
)

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.title("âš™ï¸ ì„¤ì •")
    api_key = st.text_input("OpenAI API Key", type="password", placeholder="sk-...")
    selected_model = st.selectbox("ëª¨ë¸ ì„ íƒ", ["gpt-4o", "gpt-4o-mini"], index=0)
    uploaded_file = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])
    
    st.divider()
    st.subheader("ğŸ“ ì˜ì—­ ë„ˆë¹„ ì¡°ì ˆ")
    w_left = st.slider("ë²ˆì—­ ì˜ì—­", 0.5, 4.0, 2.0, 0.1)
    w_mid = st.slider("ì›ë³¸ ì˜ì—­", 0.5, 4.0, 1.4, 0.1)
    w_right = st.slider("ìš”ì•½/ì±—ë´‡ ì˜ì—­", 0.5, 4.0, 1.2, 0.1)

st.title("ìœ ì¬ìš° Custom AI")

if uploaded_file and api_key:
    try:
        client = OpenAI(api_key=api_key)
        pdf_data = uploaded_file.getvalue()
        doc = fitz.open(stream=pdf_data, filetype="pdf")
        total_pages = len(doc)

        # ì „ì²´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì±—ë´‡ í•™ìŠµìš©)
        if not st.session_state.full_text:
            all_text = ""
            for p in doc:
                all_text += p.get_text()
            st.session_state.full_text = all_text

        # í˜ì´ì§€ ì´ë™ ì»¨íŠ¸ë¡¤
        col_nav1, col_nav2, col_nav3 = st.columns([1, 1, 1])
        with col_nav1:
            if st.button("ì´ì „ í˜ì´ì§€") and st.session_state.page_num > 0:
                st.session_state.page_num -= 1
        with col_nav2:
            st.write(f"í˜ì´ì§€: {st.session_state.page_num + 1} / {total_pages}")
        with col_nav3:
            if st.button("ë‹¤ìŒ í˜ì´ì§€") and st.session_state.page_num < total_pages - 1:
                st.session_state.page_num += 1

        # í™”ë©´ 3ë‹¨ êµ¬ì„±
        col_left, col_mid, col_right = st.columns([w_left, w_mid, w_right])
        
        current_idx = st.session_state.page_num
        page = doc.load_page(current_idx)
        page_text = page.get_text()
        
        # 1. ì¤‘ì•™: ì›ë³¸ PDF
        with col_mid:
            pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
            st.image(pix.tobytes("png"), use_container_width=True)

        # 2. ì™¼ìª½: ë²ˆì—­ (AI ì²˜ë¦¬)
        if current_idx not in st.session_state.processed_data:
            with st.spinner("ë¶„ì„ ì¤‘..."):
                t_res = client.chat.completions.create(
                    model=selected_model,
                    messages=[{"role": "system", "content": "ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì´ í˜ì´ì§€ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”."},
                              {"role": "user", "content": page_text}]
                )
                s_res = client.chat.completions.create(
                    model=selected_model,
                    messages=[{"role": "system", "content": "ì´ í˜ì´ì§€ì˜ í•µì‹¬ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ì„¸ìš”."},
                              {"role": "user", "content": page_text}]
                )
                st.session_state.processed_data[current_idx] = {
                    "trans": t_res.choices[0].message.content,
                    "sum": s_res.choices[0].message.content
                }

        with col_left:
            st.subheader("í•œêµ­ì–´ ë²ˆì—­")
            st.write(st.session_state.processed_data[current_idx]["trans"])

        # 3. ì˜¤ë¥¸ìª½: ìš”ì•½ ë° ì±—ë´‡ (ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì „ìš© ëª¨ë¸)
        with col_right:
            st.subheader("ìš”ì•½ ë° í•µì‹¬")
            st.write(st.session_state.processed_data[current_idx]["sum"])
            
            st.divider()
            st.subheader("ğŸ’¬ PDF ì „ìš© ì±—ë´‡")
            
            # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
            for chat in st.session_state.chat_history:
                with st.chat_message(chat["role"]):
                    st.markdown(chat["content"])

            # ì±„íŒ… ì…ë ¥ì°½
            if prompt := st.chat_input("ì´ ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"):
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    # PDF ì „ì²´ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì£¼ì…
                    response = client.chat.completions.create(
                        model=selected_model,
                        messages=[
                            {"role": "system", "content": f"ë‹¹ì‹ ì€ ì œê³µëœ PDF ë¬¸ì„œì˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  í•˜ì„¸ìš”.\n\n[ë¬¸ì„œ ë‚´ìš©]\n{st.session_state.full_text[:15000]}"}, # í† í° ì œí•œì„ ê³ ë ¤í•´ ì•ë¶€ë¶„ ìœ„ì£¼ ì œê³µ
                            *st.session_state.chat_history
                        ]
                    )
                    answer = response.choices[0].message.content
                    st.markdown(answer)
                    st.session_state.chat_history.append({"role": "assistant", "content": answer})

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: {str(e)}")
elif not api_key:
    st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
else:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")